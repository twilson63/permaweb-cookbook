# [ANS-103: 随机访问的简洁证明](https://github.com/ArweaveTeam/arweave-standards/blob/master/ans/ANS-103.md)

状态：草案  
作者：Sam Williams <sam@arweave.org>, Lev Berman <ldmberman@protonmail.com>

## 摘要

本文件描述 Arweave 网络基于在最新共识认可的 blockweave 状态推导出的一组历史 chunk 中竞争寻找到过去数据 chunk 的新共识机制。

## 动机

在撰写本规范时，Arweave 网络采用的共识机制为经典的工作量证明（Proof of Work），并额外要求在哈希前像中包含一个过去数据的 chunk（最大 256 KiB），该 chunk 由最新的 blockweave 状态以确定性方式决定。

虽然此方式鼓励网络保存历史数据，但并未对矿工为了保持竞争力而需存取数据的速度施加显著限制。具体而言，矿工可以从远程存储池获益。此外，结合计算池时，通过千兆位网络连接可对数百万客户端每秒提供工作量证明前像。Arweave 网络中出现的存储与计算池可由公开节点数量减少、网络算力与声称属于该池的人数同时增加所证明。

因此，新的共识算法的首要目标是让矿工的挖矿优势随着存取数据速度的提升而急剧增加，从而更积极地促进数据复制。

第二个同样重要的目标是降低网络的能耗。工作量证明网络以其高能耗著称（参见链接）。降低能耗可减少碳足迹，而碳足迹被普遍认为对地球环境极为不利。我们认为共识机制的环境友善性对 Arweave 平台的长期可持续性至关重要。

总结来说，此处描述的共识算法旨在达成两个主要目标：

- 使矿工不再被动从网络按需检索数据；换言之，鼓励矿工将数据存储在尽可能接近挖矿机的位置。
- 降低网络的能耗。

## 参考实现

[链接](https://github.com/ArweaveTeam/arweave/pull/269).

## 规范

### 先决条件

1. 已建立索引的数据集

新机制的核心为持续检索过去数据的 chunk（以下简称 chunk）。每个 chunk 以全局偏移量（global offset）标识，因为我们希望使任何比特的拥有权都受到同等激励。因此，必须对整个 weave 建立索引，以便每个 chunk 能够依其全局偏移量被快速存取。

自 2.1 版本起，Arweave 的 Erlang 客户端维护此类索引。

2. 慢速哈希（Slow Hash）

共识机制需要一种确定性但不可预测的方式来选择候选 chunk，以迫使矿工持续存取存储。但选择候选 chunk 不能过于简单，否则矿工会减少其实际处理的 chunk 数量。这会带来两种威胁。一是计算成本相对于为达成相同中奖概率而需额外存储数据的成本过低。二是现有计算技术虽然比存储整个 weave 贵，但效率高到可以胜过即便是最有效率的数据检索型客户端。

自 1.7 版本起，Arweave 协议采用 RandomX，一种为通用 CPU 最优化的工作量证明算法。

### 算法描述

每个区块唯一地定义一个搜索空间（Search Space）——在 [0, 在某区块时的 weave 大小（搜索空间上界）] 区间内的一组偏移位（回溯字节 Recall Bytes）。

#### 矿工步骤

- 生成一个随机 nonce，并对包含当前状态、候选区块与 nonce 的 Merkle 树哈希产生一个慢速哈希 (H0)。
- 从 H0、前一区块的哈希（PrevH）和搜索空间上界计算唯一的回溯字节（Recall Byte）。
- 在本地存储中搜索包含该回溯字节的 chunk。如果未找到，从第一步重试。
- 对包含第一步计算出的慢速哈希与所找到 chunk 的 Merkle 树哈希计算一个快速哈希。
- 检查计算出的哈希是否大于当前挖矿难度（将哈希视为二进位大端表示的数值后比较）。若否，从第一步重试；若是，则打包并广播该区块（区块包含 nonce 与 chunk）。

我们将解答 chunk 连同其在 blockweave 中包含性的 Merkle 证明称为“随机存取简洁证明”（Succinct Proof of Random Access，或 SPoRA），并用此作为新共识机制的名称。

#### 验证者步骤

对矿工步骤执行一次迭代，其中 nonce 与 chunk 从已验证的区块中取得。

#### 理由

##### 搜索空间限制

1. 搜索空间需要足够大，原因有二：

- 使得按需下载整个搜索空间变得代价高昂；注意，先前的共识机制可视为 SPoRA 的一个极端情形，当搜索空间仅包含单一 chunk 时即为先前机制；按需将数据提供给计算代理的效率取决于网络带宽，而网络带宽会随时间成长（参见链接）。
- 使得以哈希运算来弥补本地数据缺乏的做法变得代价高昂。

2. 另一方面，搜索空间需要足够小，以激励矿工复制 weave 中较稀有的部分，这将使得在特定区段复制较多数据的矿工相对于复制较少数据的矿工获得优势。

我们选择将搜索空间大小设为 weave 的 10%。在此情况下，若 10% 的矿工在网络上各自存储独特的 10% weave，而其他节点皆存储 90% 的 weave，前者在效率上大约比其余矿工高 1.2 倍。该结论对 RandomX 哈希计算时间与查找 chunk 所需时间之比在不同取值下均成立。

#### 伪代码

[The ar_deep_hash definition](https://fc6nvgm24f3hywasovgsmhl4kl5x34rj24shjvwql4xpj7nnonzq.arweave.net/KLzamZrhdnxYEnVNJh18Uvt98inXJHTW0F8u9P2tc3M).

```
mine(Nonce, BlockPreimage, PrevH, SearchSpaceUpperBound):
	// 计算慢速哈希。
    H0 := randomx_hash(concat(Nonce, BlockPreimage))
    RecallByte := pick_recall_byte(H0, PrevH, SearchSpaceUpperBound)
    // 在本地存储中搜索包含 Recall Byte 的 chunk。
    SPoA := get_spoa_by_byte(RecallByte)
    if SPoA == not_found
        mine(random_nonce(), BlockPreimage, PrevH, SearchSpaceUpperBound)
    Chunk := get_chunk(SPoA)
    SolutionHash := randomx_hash(concat(H0, PrevH, Timestamp, Chunk))
    if validate(Candidate, Diff)
        return
    mine(random_nonce(), BlockPreimage, PrevH, SearchSpaceUpperBound)

pick_recall_byte(H0, PrevH, SearchSpaceUpperBound):
    SubspaceNumber := remainder(hash_to_number(H0), SUBSPACES_COUNT)
    SearchSpaceSize := integer_division(SearchSpaceUpperBound, 10)
    EvenSubspaceSize := integer_division(SearchSpaceUpperBound, SUBSPACES_COUNT)
    SearchSubspaceSize := integer_division(SearchSpaceSize, SUBSPACES_COUNT)
    SubspaceStart := SubspaceNumber * EvenSubspaceSize
    SubspaceSize := min(SearchSpaceUpperBound - SubspaceStart, EvenSubspaceSize)
    EncodedSubspaceNumber := number_to_binary(SubspaceNumber)
    SearchSubspaceSeed := hash_to_number(sha256(concat(PrevH, EncodedSubspaceNumber)))
    SearchSubspaceStart := remainder(SearchSubspaceSeed, SubspaceSize)
    SearchSubspaceByteSeed := hash_to_number(sha256(H))
    SearchSubspaceByte := remainder(SearchSubspaceByteSeed, SearchSubspaceSize)
    return AbsoluteSubspaceStart + remainder(SearchSubspaceStart + SearchSubspaceByte, SubspaceSize)
```

## 相关工作

此工作深受 Microsoft Research 的 Andrew Miller、Ari Juels、Elaine Shi、Bryan Parno 与 Jonathan Katz 所著论文 “Permacoin: Repurposing Bitcoin Work for Data Preservation” 的启发。

我们建议使用现有、持续成长且始终可取得的 Arweave 数据集，而非由受信任的经销者预先生成的数据集。我们使用一种专门的、抗专用硬件的慢速哈希来使得用计算来补偿本地数据不足变得代价高昂。最后，我们为网络提供激励，促使数据均匀复制。
