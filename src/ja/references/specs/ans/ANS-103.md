# [ANS-103: Succinct Proofs of Random Access](https://github.com/ArweaveTeam/arweave-standards/blob/master/ans/ANS-103.md)

状態: 草案  
著者: Sam Williams <sam@arweave.org>, Lev Berman <ldmberman@protonmail.com>

## 概要

本書は、最新の合意済み blockweave 状態から導出される履歴チャンクの集合内で過去データのチャンクを見つける競争に基づく、Arweave ネットワーク向けの新しいコンセンサス機構について記述します。

## 動機

本仕様作成時点における Arweave ネットワークのコンセンサス機構は、追加要件としてハッシュ前像に過去データのチャンク（最大 256 KiB）を含めることを求める古典的な Proof of Work（PoW）になっています。含めるチャンクは最新の blockweave 状態から決定論的に決定されます。

このアプローチはネットワークに歴史データを保持するインセンティブを与えますが、マイナーが競争力を保つために必要なデータアクセス速度に対して有意な制約を課してはいません。具体的には、マイナーはリモートストレージプールの利用から利益を得ることができます。さらに、計算プールと組み合わせることで、Gbit のインターネット回線を介して秒間数百万クライアントに対して Proof of Work 前像を提供することが可能です。ストレージと計算のプールは、公開ノード数の減少とネットワークのハッシュパワーの同時増加、およびプールの一部であると主張する人々の増加という形で Arweave ネットワーク上で実証されています。

したがって、新しいコンセンサスアルゴリズムの第一の目的は、データへのアクセス速度が増すにつれてマイニング上の優位性が急激に増加するようにし、レプリケーションをより強力に促進することです。

第二の、しかし同等に重要な目的は、ネットワークが消費するエネルギーを削減することです。Proof of Work ネットワークはそのエネルギー集約性で知られており（参照リンク）、エネルギー消費の削減は一般に地球環境への有害さを軽減します。コンセンサスメカニズムの環境適合性は Arweave プラットフォームの長期的持続可能性にとって重要であると考えます。

要約すると、ここで記述するコンセンサスアルゴリズムは以下の 2 つの主要目標を目指します。

- マイナーがネットワークからオンデマンドでデータを取得することに対するインセンティブを減らす。言い換えれば、マイナーが可能な限りマイニング装置の近くにデータを保存することを奨励する。
- ネットワークのエネルギー消費を削減する。

## 参照実装

[Link](https://github.com/ArweaveTeam/arweave/pull/269).

## 仕様

### 前提条件

1. インデックス化されたデータセット

新機構の核は、過去データのチャンクを継続的に取得することです。すべてのチャンクはグローバルオフセットによって識別されます。任意のバイトの所持が等しくインセンティブされるようにしたいためです。したがって、全 weave をインデックス化し、任意のチャンクがグローバルオフセットによって迅速にアクセス可能である必要があります。

リリース 2.1 以降、Arweave の Erlang クライアントはそのようなインデックスを維持します。

2. スローハッシュ

コンセンサス機構は、候補チャンクを決定するために決定論的で予測不可能な方法を必要とします。これによりマイナーは継続的にストレージへアクセスすることを強制されます。しかし、候補チャンクの選択があまりにも容易だと、マイナーは実際に扱うチャンク数を減らすことが可能になります。これには二つの脅威が関連します。一つは、同じ報酬確率を得るために必要な追加データの保管コストと比較して計算支出のコストが低くなること。もう一つは、既存の計算技術が、全 weave を保管するよりは高価であるものの、非常に効率的であってデータ取得ベースのクライアントよりも優れてしまうことです。

リリース 1.7 以降、Arweave プロトコルは汎用 CPU に最適化された Proof-of-Work アルゴリズムである RandomX を利用しています。

### アルゴリズムの説明

各ブロックは一意に Search Space（検索空間）を定めます。これは [0, ブロック時点での weave サイズ（Search Space Upper Bound）] 区間上のオフセット（Recall Bytes）の集合です。

#### マイナーの手順

- ランダムな nonce を生成し、現在の状態、候補ブロック、および nonce を含む Merkle tree のハッシュのスローハッシュ（H0）を生成する。
- H0、前のブロックのハッシュ（PrevH）、および Search Space Upper Bound から一意の Recall Byte を算出する。
- 計算された Recall Byte を含むチャンクをローカルストレージ内で検索する。見つからなければ、最初のステップからやり直す。
- 最初のステップで計算したスローハッシュと見つかったチャンクを含む Merkle tree のハッシュに対して高速ハッシュを計算する。
- 計算されたハッシュが現在のマイニング難易度より大きいかどうかを確認する（バイナリ桁の大きい順表現から算出した数と比較して大きいかどうか）。大きくなければ最初のステップからやり直す。条件を満たす場合、ブロックをパックして配布する（ブロックには nonce とチャンクが含まれる）。

解決チャンクとその blockweave への包含を示す Merkle 証明を合わせて Succinct Proof of Random Access（SPoRA）と呼び、新しいコンセンサス機構の名称として使用します。

#### 検証者の手順

検証済みブロックに nonce とチャンクが含まれていることを前提に、マイナー手順を一回実行します。

#### 根拠

##### 検索空間の制約

1. 検索空間は二つの理由で十分に大きくある必要があります:

- オンデマンドで検索空間全体をダウンロードすることが事実上高コストになるようにすること。なお、従来のコンセンサス機構は検索空間が単一チャンクからなる SPoRA の特殊ケースと見なせます。計算エージェントに対してデータをオンデマンドで提供する効率はネットワーク帯域幅に依存し、これは時間とともに増加しています（参照リンク）。
- ローカルデータの不足をハッシュ計算で補うことを事実上高コストにすること。

2. 一方で、検索空間は weave のより希少な部分をレプリケートするインセンティブを与えるために十分に小さくある必要があります。これにより、対応するブロック時点で対応領域のより多くを複製しているマイナーは、そうでないマイナーに対して優位性を得ます。

我々は検索空間のサイズを weave の 10% とします。この場合、ネットワーク上で各自が weave の 90% を保存している環境において、固有に 10% を保存するマイナー群の 10% は、残りのマイナー群より概ね 1.2 倍効率的になります。これは RandomX ハッシュの計算に要する時間とチャンクのルックアップに要する時間の比率に対して様々な比率で成立します。

#### 疑似コード

[The ar_deep_hash definition](https://fc6nvgm24f3hywasovgsmhl4kl5x34rj24shjvwql4xpj7nnonzq.arweave.net/KLzamZrhdnxYEnVNJh18Uvt98inXJHTW0F8u9P2tc3M).

```
mine(Nonce, BlockPreimage, PrevH, SearchSpaceUpperBound):
	// Compute a slow hash.
    H0 := randomx_hash(concat(Nonce, BlockPreimage))
    RecallByte := pick_recall_byte(H0, PrevH, SearchSpaceUpperBound)
    // Search the local storage for the chunk containing Recall Byte.
    SPoA := get_spoa_by_byte(RecallByte)
    if SPoA == not_found
        mine(random_nonce(), BlockPreimage, PrevH, SearchSpaceUpperBound)
    Chunk := get_chunk(SPoA)
    SolutionHash := randomx_hash(concat(H0, PrevH, Timestamp, Chunk))
    if validate(Candidate, Diff)
        return
    mine(random_nonce(), BlockPreimage, PrevH, SearchSpaceUpperBound)

pick_recall_byte(H0, PrevH, SearchSpaceUpperBound):
    SubspaceNumber := remainder(hash_to_number(H0), SUBSPACES_COUNT)
    SearchSpaceSize := integer_division(SearchSpaceUpperBound, 10)
    EvenSubspaceSize := integer_division(SearchSpaceUpperBound, SUBSPACES_COUNT)
    SearchSubspaceSize := integer_division(SearchSpaceSize, SUBSPACES_COUNT)
    SubspaceStart := SubspaceNumber * EvenSubspaceSize
    SubspaceSize := min(SearchSpaceUpperBound - SubspaceStart, EvenSubspaceSize)
    EncodedSubspaceNumber := number_to_binary(SubspaceNumber)
    SearchSubspaceSeed := hash_to_number(sha256(concat(PrevH, EncodedSubspaceNumber)))
    SearchSubspaceStart := remainder(SearchSubspaceSeed, SubspaceSize)
    SearchSubspaceByteSeed := hash_to_number(sha256(H))
    SearchSubspaceByte := remainder(SearchSubspaceByteSeed, SearchSubspaceSize)
    return AbsoluteSubspaceStart + remainder(SearchSubspaceStart + SearchSubspaceByte, SubspaceSize)
```

## 関連研究

本研究は Microsoft Research の Andrew Miller、Ari Juels、Elaine Shi、Bryan Parno、Jonathan Katz による「Permacoin: Repurposing Bitcoin Work for Data Preservation」から強い影響を受けています（参照リンク）。

我々は、信頼されたディーラーによって事前生成されたデータセットの代わりに、既存で成長し常にアクセス可能な Arweave データセットを利用することを提案します。ローカルデータの欠如を計算で補うことを事実上高コストにするために、ハードウェア耐性のあるスローハッシュを使用します。最後に、ネットワークにデータを均一にレプリケートするインセンティブを提供します。
