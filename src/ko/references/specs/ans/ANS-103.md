# [ANS-103: 임의 접근에 대한 간결한 증명](https://github.com/ArweaveTeam/arweave-standards/blob/master/ans/ANS-103.md)

상태: 초안  
저자: Sam Williams <sam@arweave.org>, Lev Berman <ldmberman@protonmail.com>

## 초록

이 문서는 최신 합의된 블록위브 상태에서 유추된 일련의 과거 청크들 중 과거 데이터의 한 청크를 찾기 위한 경쟁에 기반한 Arweave 네트워크의 새로운 합의 메커니즘을 설명한다.

## 동기

이 명세가 작성된 시점에서 Arweave 네트워크가 사용하는 합의 메커니즘은 추가적인 요구사항으로 해시 프리이미지에 과거 데이터의 한 청크(최대 256 KiB)를 포함하도록 하는 고전적인 작업증명(Proof of Work)이다. 이 청크는 블록위브의 최신 상태에 의해 결정적으로 결정된다.

이 접근법은 네트워크가 과거 데이터를 보관하도록 유도하지만, 채굴자가 경쟁력을 유지하기 위해 필요한 데이터 접근 속도에 대해 실질적인 제약을 부과하지 않는다. 구체적으로, 채굴자는 원격 스토리지 풀을 이용함으로써 이점을 얻을 수 있다. 더 나아가 계산 풀과 결합하면 Gbit 인터넷 링크를 통해 초당 수백만 클라이언트에게 작업증명 프리이미지를 서비스할 수 있다. Arweave 네트워크에서는 공개 노드 수 감소와 네트워크 해시파워의 동시 증가 및 자신들이 풀의 일부라고 주장하는 사람들의 증가로 스토리지 및 계산 풀이 존재함이 입증되었다.

따라서 새로운 합의 알고리즘의 첫 번째 목표는 데이터 접근 속도가 증가함에 따라 채굴 이점이 급격히 커지도록 하여 복제를 보다 적극적으로 촉진하는 것이다.

두 번째이자 덜 중요하지 않은 목표는 네트워크가 소비하는 에너지를 줄이는 것이다. 작업증명 네트워크는 높은 에너지 소비로 [잘 알려져 있으며](https://bxykxaboh2oblctbs36xg6rahncvn2lqe7xh43pd4waavej4wczq.arweave.net/DfCrgC4-nBWKYZb9c3ogO0VW6XAn7n5t4-WACpE8sLM) 에너지 소비를 줄이면 탄소발자국을 감소시킬 수 있다. 이는 지구에 매우 해로운 것으로 널리 여겨진다. 우리는 합의 메커니즘의 환경 친화성이 Arweave 플랫폼의 장기적인 지속 가능성에 매우 중요하다고 믿는다.

요약하면, 여기서 설명하는 합의 알고리즘은 두 가지 주요 목표를 가진다.

- 채굴자가 네트워크에서 요청 시 데이터를 가져오는 것을 억제한다. 즉, 채굴자가 데이터를 채굴 장비에 가능한 한 가깝게 저장하도록 인센티브를 제공한다.
- 네트워크의 에너지 소비를 줄인다.

## 참고 구현

[Link](https://github.com/ArweaveTeam/arweave/pull/269).

## 명세

### 전제 조건

1. 인덱스된 데이터셋

새 메커니즘의 핵심은 과거 데이터 청크의 연속적인 검색이다. 모든 청크는 글로벌 오프셋으로 식별되며, 이는 어떤 바이트의 소유도 동일하게 인센티브화되도록 하기 위함이다. 따라서 전체 위브는 모든 청크가 글로벌 오프셋으로 빠르게 접근 가능하도록 인덱스되어야 한다.

릴리스 2.1부터 Arweave Erlang 클라이언트는 이러한 인덱스를 유지한다.

2. 느린 해시

합의 메커니즘은 후보 청크를 선택하기 위한 결정적이지만 예측 불가능한 방법을 필요로 하며, 채굴자가 지속적으로 스토리지에 접근하도록 만든다. 그러나 후보 청크를 선택하는 작업이 너무 쉬우면 채굴자가 실제로 작업하는 청크 수를 줄일 수 있다. 이에 관련된 두 가지 위협이 있다. 하나는 보상 확률을 동일하게 유지하기 위해 필요한 추가 데이터를 저장하는 비용에 비해 계산 지출 비용이 낮아지는 것이다. 두 번째 위협은 전체 위브를 저장하는 것보다 비싸긴 하지만, 데이터 검색 기반 클라이언트를 능가할 정도로 매우 효율적인 기존 계산 기술이다.

릴리스 1.7부터 Arweave 프로토콜은 범용 CPU에 최적화된 작업증명 알고리즘인 [RandomX](https://44jxru4mdgbtd66dlzjlc3huktqmmzufomg5p24jl66zyut562yq.arweave.net/5xN404wZgzH7w15SsWz0VODGZoVzDdfriV-9nFJ99rE)를 사용한다.

### 알고리즘 설명

각 블록은 고유하게 검색 공간(Search Space)을 결정한다 — [0, 특정 블록에서의 위브 크기(검색 공간 상한)] 구간의 오프셋 집합(Recall Bytes).

#### 채굴자 단계

- 랜덤 논스를 생성하고 현재 상태, 후보 블록, 논스를 포함하는 머클 트리의 해시의 느린 해시(H0)를 생성한다.
- H0, 이전 블록의 해시(PrevH), 및 검색 공간 상한으로부터 고유한 리콜 바이트를 계산한다.
- 계산된 리콜 바이트를 포함하는 청크를 로컬 스토리지에서 검색한다. 찾지 못하면 첫 번째 단계부터 반복한다.
- 첫 단계에서 계산된 느린 해시와 찾은 청크를 포함하는 머클 트리의 해시의 빠른 해시를 계산한다.
- 계산된 해시가 현재 채굴 난이도보다 큰지(이진수 빅엔디안 표현에서 더 큰 수인지) 확인한다. 그렇지 않으면 첫 번째 단계부터 반복한다. 그렇다면 블록을 패킹하고 배포한다(블록은 논스와 청크를 포함한다).

해결 청크와 블록위브에 포함되었다는 머클 증명을 함께 우리는 Succinct Proof of Random Access(또는 SPoRA)라고 부르며, 새로운 합의 메커니즘의 명칭으로 사용한다.

#### 검증자 단계

검증된 블록에서 논스와 청크가 발견된 채굴자 단계의 한 반복을 수행한다.

#### 근거

##### 검색 공간 제약

1. 검색 공간은 다음 두 가지 이유로 충분히 커야 한다:

- 전체 검색 공간을 필요한 시점에 다운로드하는 것을 사실상 비경제적으로 만들기 위해; 이전 합의 메커니즘은 검색 공간이 단일 청크로 구성된 SPoRA의 특수한 경우로 볼 수 있다; 컴퓨팅 에이전트에 데이터를 온디맨드로 서빙하는 효율성은 네트워크 대역폭에 의존하며, 이는 시간이 지남에 따라 [증가한다](https://dnodjq6x4sx7jelro3vmus25v3xpjlgox3u6xessdjv6mtuwrkmq.arweave.net/G1w0w9fkr_SRcXbqyktdru70rM6-6euSUhpr5k6Wipk).
- 로컬 데이터 부족을 해시 계산으로 보상하는 것을 사실상 비경제적으로 만들기 위해.

2. 반면에 검색 공간은 위브의 더 희귀한 부분들을 채굴자가 복제하도록 인센티브를 제공할 만큼 충분히 작아야 한다. 이는 해당 블록들에서 해당 영역을 덜 복제한 채굴자들보다 더 큰 이점을 제공한다.

우리는 검색 공간 크기를 위브의 10%로 선택한다. 이 경우, 네트워크에서 각자가 위브의 90%를 저장하는 환경에서 고유하게 위브의 10%를 저장하는 채굴자 10%는 나머지 채굴자들보다 대략 1.2배 더 효율적이다. 이는 RandomX 해시를 계산하는 데 걸리는 시간과 청크를 조회하는 데 걸리는 시간의 다양한 비율에 대해 성립한다.

#### 의사 코드

[The ar_deep_hash definition](https://fc6nvgm24f3hywasovgsmhl4kl5x34rj24shjvwql4xpj7nnonzq.arweave.net/KLzamZrhdnxYEnVNJh18Uvt98inXJHTW0F8u9P2tc3M).

```
mine(Nonce, BlockPreimage, PrevH, SearchSpaceUpperBound):
	// Compute a slow hash.
    H0 := randomx_hash(concat(Nonce, BlockPreimage))
    RecallByte := pick_recall_byte(H0, PrevH, SearchSpaceUpperBound)
    // Search the local storage for the chunk containing Recall Byte.
    SPoA := get_spoa_by_byte(RecallByte)
    if SPoA == not_found
        mine(random_nonce(), BlockPreimage, PrevH, SearchSpaceUpperBound)
    Chunk := get_chunk(SPoA)
    SolutionHash := randomx_hash(concat(H0, PrevH, Timestamp, Chunk))
    if validate(Candidate, Diff)
        return
    mine(random_nonce(), BlockPreimage, PrevH, SearchSpaceUpperBound)

pick_recall_byte(H0, PrevH, SearchSpaceUpperBound):
    SubspaceNumber := remainder(hash_to_number(H0), SUBSPACES_COUNT)
    SearchSpaceSize := integer_division(SearchSpaceUpperBound, 10)
    EvenSubspaceSize := integer_division(SearchSpaceUpperBound, SUBSPACES_COUNT)
    SearchSubspaceSize := integer_division(SearchSpaceSize, SUBSPACES_COUNT)
    SubspaceStart := SubspaceNumber * EvenSubspaceSize
    SubspaceSize := min(SearchSpaceUpperBound - SubspaceStart, EvenSubspaceSize)
    EncodedSubspaceNumber := number_to_binary(SubspaceNumber)
    SearchSubspaceSeed := hash_to_number(sha256(concat(PrevH, EncodedSubspaceNumber)))
    SearchSubspaceStart := remainder(SearchSubspaceSeed, SubspaceSize)
    SearchSubspaceByteSeed := hash_to_number(sha256(H))
    SearchSubspaceByte := remainder(SearchSubspaceByteSeed, SearchSubspaceSize)
    return AbsoluteSubspaceStart + remainder(SearchSubspaceStart + SearchSubspaceByte, SubspaceSize)
```

## 관련 연구

이 작업은 Microsoft Research의 Andrew Miller, Ari Juels, Elaine Shi, Bryan Parno, Jonathan Katz가 작성한 [Permacoin: Repurposing Bitcoin Work for Data Preservation](https://y7h7r6qdh3rdcn4vczpa6tbrhp5hcs5bid3kg7olifzb55slpqha.arweave.net/x8_4-gM-4jE3lRZeD0wxO_pxS6FA9qN9y0FyHvZLfA4)에 크게 영감을 받았다.

우리는 신뢰할 수 있는 딜러에 의해 사전 생성된 데이터셋 대신 기존의, 성장하는, 항상 접근 가능한 Arweave 데이터셋을 사용할 것을 제안한다. 지역 데이터 부족을 계산으로 보상하는 것을 사실상 비경제적으로 만들기 위해 특수화된 하드웨어에 강한 느린 해시를 사용한다. 마지막으로, 네트워크가 데이터를 균일하게 복제하도록 인센티브를 제공한다.
