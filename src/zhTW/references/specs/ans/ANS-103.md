# [ANS-103: Succinct Proofs of Random Access](https://github.com/ArweaveTeam/arweave-standards/blob/master/ans/ANS-103.md)

狀態：草案  
作者：Sam Williams <sam@arweave.org>, Lev Berman <ldmberman@protonmail.com>

## 摘要

本文件描述 Arweave 網路基於在最新共識認可的 blockweave 狀態推導出的一組歷史 chunk 中競爭尋找過去資料 chunk 的新共識機制。

## 動機

在撰寫本規範時，Arweave 網路採用的共識機制為經典的工作量證明（Proof of Work），並額外要求在雜湊前映像中包含一個過去資料的 chunk（最大 256 KiB），該 chunk 由最新的 blockweave 狀態以決定性方式決定。

雖然此方式鼓勵網路保存歷史資料，但並未對礦工為了保持競爭力而需存取資料的速度施加顯著限制。具體而言，礦工可以從遠端儲存池獲益。此外，結合計算池時，透過千兆位元網路連線可對數百萬客戶端每秒提供工作量證明前映像。Arweave 網路中出現的儲存與計算池可由公開節點數量減少、網路算力與聲稱屬於該池的人數同時增加所證明。

因此，新的共識演算法的首要目標是讓礦工的挖礦優勢隨著存取資料速度的提升而急劇增加，從而更積極地促進資料複製。

第二個同樣重要的目標是降低網路的能耗。工作量證明網路以其高能耗著稱（參見連結）。降低能耗可減少碳足跡，而碳足跡被普遍認為對地球環境極為不利。我們認為共識機制的環境友善性對 Arweave 平台的長期永續性至關重要。

總結來說，此處描述的共識演算法旨在達成兩個主要目標：

- 使礦工不再被動從網路按需檢索資料；換言之，鼓勵礦工將資料儲存在盡可能接近挖礦機的位置。
- 降低網路的能耗。

## 參考實作

[Link](https://github.com/ArweaveTeam/arweave/pull/269).

## 規範

### 先決條件

1. 已建立索引的資料集

新機制的核心為持續檢索過去資料的 chunk（以下簡稱 chunk）。每個 chunk 以全域偏移量（global offset）標識，因為我們希望使任何位元的擁有權都受到同等激勵。因此，必須對整個 weave 建立索引，以便每個 chunk 能夠依其全域偏移量被快速存取。

自 2.1 版本起，Arweave 的 Erlang 用戶端維護此類索引。

2. 慢速雜湊（Slow Hash）

共識機制需要一種決定性但不可預測的方式來選擇候選 chunk，以迫使礦工持續存取儲存。但選擇候選 chunk 不能過於簡單，否則礦工會減少其實際處理的 chunk 數量。這會帶來兩種威脅。一是計算成本相對於為達成相同中獎概率而需額外儲存資料的成本過低。二是現有計算技術雖然比儲存整個 weave 貴，但效率高到可以勝過即便是最有效率的資料檢索型客戶端。

自 1.7 版本起，Arweave 協議採用 RandomX，一種為通用 CPU 最佳化的工作量證明演算法。

### 演算法描述

每個區塊唯一地定義一個搜尋空間（Search Space）——在 [0, 在某區塊時的 weave 大小（搜尋空間上界）] 區間內的一組偏移位（回溯位元組 Recall Bytes）。

#### 礦工步驟

- 生成一個隨機 nonce，並對包含當前狀態、候選區塊與 nonce 的 Merkle 樹雜湊產生一個慢速雜湊 (H0)。
- 從 H0、前一區塊的雜湊（PrevH）和搜尋空間上界計算唯一的回溯位元組（Recall Byte）。
- 在本地儲存中搜尋包含該回溯位元組的 chunk。如果未找到，從第一步重試。
- 對包含第一步計算出的慢速雜湊與所找到 chunk 的 Merkle 樹雜湊計算一個快速雜湊。
- 檢查計算出的雜湊是否大於當前挖礦難度（將雜湊視為二進位大端表示的數值後比較）。若否，從第一步重試；若是，則打包並廣播該區塊（區塊包含 nonce 與 chunk）。

我們將解答 chunk 連同其在 blockweave 中包含性的 Merkle 證明稱為「隨機存取簡潔證明」（Succinct Proof of Random Access，或 SPoRA），並用此作為新共識機制的名稱。

#### 驗證者步驟

對礦工步驟執行一次迭代，其中 nonce 與 chunk 從已驗證的區塊中取得。

#### 理由

##### 搜尋空間限制

1. 搜尋空間需要足夠大，原因有二：

- 使得按需下載整個搜尋空間變得代價高昂；注意，先前的共識機制可視為 SPoRA 的一個極端情況，當搜尋空間僅包含單一 chunk 時即為先前機制；按需將資料提供給計算代理的效率取決於網路頻寬，而網路頻寬會隨時間成長（參見連結）。
- 使得以雜湊運算來彌補本地資料缺乏的做法變得代價高昂。

2. 另一方面，搜尋空間需要足夠小，以激勵礦工複製 weave 中較稀有的部分，這將使得在特定區段複製較多資料的礦工相對於複製較少資料的礦工獲得優勢。

我們選擇將搜尋空間大小設為 weave 的 10%。在此情況下，若 10% 的礦工在網路上各自儲存獨特的 10% weave，而其他節點皆儲存 90% 的 weave，前者在效率上大約比其餘礦工高 1.2 倍。該結論對 RandomX 雜湊計算時間與查找 chunk 所需時間之比在不同取值下均成立。

#### 偽代碼

[The ar_deep_hash definition](https://fc6nvgm24f3hywasovgsmhl4kl5x34rj24shjvwql4xpj7nnonzq.arweave.net/KLzamZrhdnxYEnVNJh18Uvt98inXJHTW0F8u9P2tc3M).

```
mine(Nonce, BlockPreimage, PrevH, SearchSpaceUpperBound):
	// Compute a slow hash.
    H0 := randomx_hash(concat(Nonce, BlockPreimage))
    RecallByte := pick_recall_byte(H0, PrevH, SearchSpaceUpperBound)
    // Search the local storage for the chunk containing Recall Byte.
    SPoA := get_spoa_by_byte(RecallByte)
    if SPoA == not_found
        mine(random_nonce(), BlockPreimage, PrevH, SearchSpaceUpperBound)
    Chunk := get_chunk(SPoA)
    SolutionHash := randomx_hash(concat(H0, PrevH, Timestamp, Chunk))
    if validate(Candidate, Diff)
        return
    mine(random_nonce(), BlockPreimage, PrevH, SearchSpaceUpperBound)

pick_recall_byte(H0, PrevH, SearchSpaceUpperBound):
    SubspaceNumber := remainder(hash_to_number(H0), SUBSPACES_COUNT)
    SearchSpaceSize := integer_division(SearchSpaceUpperBound, 10)
    EvenSubspaceSize := integer_division(SearchSpaceUpperBound, SUBSPACES_COUNT)
    SearchSubspaceSize := integer_division(SearchSpaceSize, SUBSPACES_COUNT)
    SubspaceStart := SubspaceNumber * EvenSubspaceSize
    SubspaceSize := min(SearchSpaceUpperBound - SubspaceStart, EvenSubspaceSize)
    EncodedSubspaceNumber := number_to_binary(SubspaceNumber)
    SearchSubspaceSeed := hash_to_number(sha256(concat(PrevH, EncodedSubspaceNumber)))
    SearchSubspaceStart := remainder(SearchSubspaceSeed, SubspaceSize)
    SearchSubspaceByteSeed := hash_to_number(sha256(H))
    SearchSubspaceByte := remainder(SearchSubspaceByteSeed, SearchSubspaceSize)
    return AbsoluteSubspaceStart + remainder(SearchSubspaceStart + SearchSubspaceByte, SubspaceSize)
```

## 相關工作

此工作深受 Microsoft Research 的 Andrew Miller、Ari Juels、Elaine Shi、Bryan Parno 與 Jonathan Katz 所著的論文「Permacoin: Repurposing Bitcoin Work for Data Preservation」所啟發。

我們建議使用現有、持續成長且始終可取得的 Arweave 資料集，而非由受信任的經銷者預先生成的資料集。我們使用一種專門的、抗專用硬體的慢速雜湊來使得用計算來補償本地資料不足變得代價高昂。最後，我們為網路提供激勵，促使資料均勻複製。
