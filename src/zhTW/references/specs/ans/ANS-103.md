# [ANS-103：隨機存取的簡潔證明 (Succinct Proofs of Random Access)](https://github.com/ArweaveTeam/arweave-standards/blob/master/ans/ANS-103.md)

狀態：草案  
作者：Sam Williams <sam@arweave.org>, Lev Berman <ldmberman@protonmail.com>

## 摘要

本文檔描述 Arweave 網路基於在最新共識的 blockweave 狀態推斷出的一組歷史 chunk 中競爭尋找過去資料 chunk 的新共識機制。

## 動機

在本規範撰寫之時，Arweave 網路所採用的共識機制是一種經典的工作量證明（Proof of Work），並額外要求在雜湊前像中包含一個過去資料的 chunk（最多 256 KiB），該 chunk 由最新的 blockweave 狀態確定。

雖然此方法激勵網路保存歷史資料，但並未對礦工為了競爭而存取資料的速度施加顯著限制。具體來說，礦工可以受益於使用遠端儲存池。此外，結合計算池，它可以透過 Gbit 網際網路連線每秒向數百萬用戶端提供工作量證明前像。Arweave 網路中已經有儲存與計算池的跡象，表現為公開節點數量減少，同時網路算力與自稱屬於該池的人數增加。

因此，新共識演算法的第一個目標是使挖礦優勢隨資料存取速度的提升而急劇上升，更積極地促進資料的複製。

第二個同樣重要的目標是降低網路的能耗。工作量證明網路以其高能耗而聞名（參見連結）。降低能耗可減少碳足跡，而碳足跡被廣泛認為對地球有害。我們相信共識機制的環保性對 Arweave 平台的長期可持續性至關重要。

總結來說，此處描述的共識演算法旨在達成兩項主要目標：

- 不鼓勵礦工按需從網路檢索資料。換句話說，激勵礦工儘可能將資料儲存在靠近挖礦機器的位置。
- 降低網路的能源消耗。

## 參考實作

[Link](https://github.com/ArweaveTeam/arweave/pull/269)。

## 規範

### 先決條件

1. 已建立索引的資料集

新機制的核心在於持續檢索過去資料的 chunk。每個 chunk 以全域偏移（global offset）來識別，因為我們希望持有任何位元組都能獲得同等的激勵。因此，必須對整個 weave 建立索引，使得每個 chunk 可以依其全域偏移快速存取。

從 2.1 版本開始，Arweave 的 Erlang 用戶端維護此類索引。

2. 慢速雜湊

共識機制需要一種確定性但不可預測的方法來選擇候選 chunk，以迫使礦工持續存取儲存。但是，選擇候選 chunk 不能太容易，否則礦工會減少他們實際處理的 chunk 數量。這會帶來兩種威脅。一是計算開銷低於為獲得相同期望獎勵而額外存儲資料的成本。另一個威脅是現有的計算技術，雖然比完整存儲整個 weave 更昂貴，但其效率足以勝過最有效率的基於資料檢索的客戶端。

從 1.7 版本開始，Arweave 協議採用了 RandomX，一種為一般用途 CPU 最佳化的工作量證明演算法。

### 演算法描述

每個區塊唯一地決定一個搜尋空間（Search Space）——一組在 [0, 在某區塊的 weave 大小（Search Space Upper Bound）] 區間內的偏移量（Recall Bytes）。

#### 礦工步驟

- 產生隨機 nonce，並對包含當前狀態、候選區塊與 nonce 的 Merkle 樹的雜湊計算慢速雜湊 (H0)。
- 從 H0、前一個區塊的雜湊（PrevH）與搜尋空間上界計算唯一的 recall byte。
- 在本地儲存中尋找包含該 recall byte 的 chunk。若找不到，從第一步重新開始。
- 對包含第一步計算的慢速雜湊與所找到 chunk 的 Merkle 樹的雜湊計算快速雜湊。
- 檢查計算出的雜湊是否大於當前挖礦難度（以大端二進位表示的數字比較）。若不是，從第一步重新開始。若是，打包並散佈該區塊（區塊包含 nonce 與 chunk）。

我們將解題用的 chunk 連同它在 blockweave 中包含性的 Merkle 證明稱為隨機存取的簡潔證明（Succinct Proof of Random Access，或簡稱 SPoRA），並以此作為新共識機制的名稱。

#### 驗證者步驟

對區塊中找到的 nonce 與 chunk 執行一次礦工步驟中的迭代。

#### 理由

##### 搜尋空間限制

1. 搜尋空間需要夠大，原因有二：

- 使按需下載整個搜尋空間成本變得不可接受；注意，先前的共識機制可視為 SPoRA 的一個特例，其搜尋空間只包含單個 chunk；按需向計算代理提供資料的效率取決於網路頻寬，而網路頻寬會隨時間成長。
- 使以哈希補償缺乏資料的做法成本變得不可接受。

2. 另一方面，搜尋空間也需要足夠小，以激勵礦工複製 weave 中較稀有的部分，這會讓他們相較於在對應區塊對應區域複製較少資料的其他礦工擁有優勢。

我們選擇將搜尋空間大小設為 weave 的 10%。在此情況下，若網路中 10% 的礦工各自唯一地儲存 10% 的 weave，而每個節點都儲存 90% 的 weave，這些儲存獨特 10% 的礦工大約比其他礦工有效率高 1.2 倍。這一結論對於計算 RandomX 雜湊所需時間與查找一個 chunk 所需時間之比的各種比率都成立。

#### 偽代碼

[ar_deep_hash 定義](https://fc6nvgm24f3hywasovgsmhl4kl5x34rj24shjvwql4xpj7nnonzq.arweave.net/KLzamZrhdnxYEnVNJh18Uvt98inXJHTW0F8u9P2tc3M).

```
mine(Nonce, BlockPreimage, PrevH, SearchSpaceUpperBound):
	// 計算慢速雜湊。
    H0 := randomx_hash(concat(Nonce, BlockPreimage))
    RecallByte := pick_recall_byte(H0, PrevH, SearchSpaceUpperBound)
    // 在本地儲存中尋找包含 Recall Byte 的 chunk。
    SPoA := get_spoa_by_byte(RecallByte)
    if SPoA == not_found
        mine(random_nonce(), BlockPreimage, PrevH, SearchSpaceUpperBound)
    Chunk := get_chunk(SPoA)
    SolutionHash := randomx_hash(concat(H0, PrevH, Timestamp, Chunk))
    if validate(Candidate, Diff)
        return
    mine(random_nonce(), BlockPreimage, PrevH, SearchSpaceUpperBound)

pick_recall_byte(H0, PrevH, SearchSpaceUpperBound):
    SubspaceNumber := remainder(hash_to_number(H0), SUBSPACES_COUNT)
    SearchSpaceSize := integer_division(SearchSpaceUpperBound, 10)
    EvenSubspaceSize := integer_division(SearchSpaceUpperBound, SUBSPACES_COUNT)
    SearchSubspaceSize := integer_division(SearchSpaceSize, SUBSPACES_COUNT)
    SubspaceStart := SubspaceNumber * EvenSubspaceSize
    SubspaceSize := min(SearchSpaceUpperBound - SubspaceStart, EvenSubspaceSize)
    EncodedSubspaceNumber := number_to_binary(SubspaceNumber)
    SearchSubspaceSeed := hash_to_number(sha256(concat(PrevH, EncodedSubspaceNumber)))
    SearchSubspaceStart := remainder(SearchSubspaceSeed, SubspaceSize)
    SearchSubspaceByteSeed := hash_to_number(sha256(H))
    SearchSubspaceByte := remainder(SearchSubspaceByteSeed, SearchSubspaceSize)
    return AbsoluteSubspaceStart + remainder(SearchSubspaceStart + SearchSubspaceByte, SubspaceSize)
```

## 相關工作

此工作深受 Microsoft Research 的 Andrew Miller、Ari Juels、Elaine Shi、Bryan Parno 與 Jonathan Katz 所著之論文「Permacoin: Repurposing Bitcoin Work for Data Preservation」啟發。

我們建議使用現存的、持續增長且始終可得的 Arweave 資料集，而非由可信發起者預先生成的資料集。我們使用一種慢速、對專用硬體具抗性的雜湊，來使得以計算補償本地資料缺乏的做法成本不可接受。最後，我們為網路提供了均勻複製資料的激勵。
